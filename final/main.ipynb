{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from river import utils\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path):\n",
    "    utils.dump(model, path)\n",
    "    print(f\"Model saved to → {path}\")\n",
    "def load_model(path):\n",
    "    if os.path.exists(path):\n",
    "        model = utils.load(path)\n",
    "        print(f\"Model loaded from → {path}\")\n",
    "        return model\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>cpu_milli</th>\n",
       "      <th>memory_mib</th>\n",
       "      <th>num_gpu</th>\n",
       "      <th>gpu_milli</th>\n",
       "      <th>gpu_spec</th>\n",
       "      <th>qos</th>\n",
       "      <th>pod_phase</th>\n",
       "      <th>creation_time</th>\n",
       "      <th>deletion_time</th>\n",
       "      <th>scheduled_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openb-pod-0000</td>\n",
       "      <td>12500</td>\n",
       "      <td>57344</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LS</td>\n",
       "      <td>Running</td>\n",
       "      <td>10644355</td>\n",
       "      <td>10644932</td>\n",
       "      <td>10644358.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>openb-pod-0001</td>\n",
       "      <td>12500</td>\n",
       "      <td>57344</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LS</td>\n",
       "      <td>Running</td>\n",
       "      <td>11556813</td>\n",
       "      <td>11557292</td>\n",
       "      <td>11556817.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>openb-pod-0002</td>\n",
       "      <td>32000</td>\n",
       "      <td>49152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BE</td>\n",
       "      <td>Running</td>\n",
       "      <td>11412186</td>\n",
       "      <td>11412330</td>\n",
       "      <td>11412189.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>openb-pod-0003</td>\n",
       "      <td>16500</td>\n",
       "      <td>51200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LS</td>\n",
       "      <td>Running</td>\n",
       "      <td>12524063</td>\n",
       "      <td>12524844</td>\n",
       "      <td>12524064.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>openb-pod-0004</td>\n",
       "      <td>8000</td>\n",
       "      <td>30517</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BE</td>\n",
       "      <td>Running</td>\n",
       "      <td>10741000</td>\n",
       "      <td>10744539</td>\n",
       "      <td>10741002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7848</th>\n",
       "      <td>openb-pod-7848</td>\n",
       "      <td>16000</td>\n",
       "      <td>32768</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LS</td>\n",
       "      <td>Succeeded</td>\n",
       "      <td>12897160</td>\n",
       "      <td>12900786</td>\n",
       "      <td>12897161.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7849</th>\n",
       "      <td>openb-pod-7849</td>\n",
       "      <td>11400</td>\n",
       "      <td>77824</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LS</td>\n",
       "      <td>Running</td>\n",
       "      <td>12897659</td>\n",
       "      <td>12898203</td>\n",
       "      <td>12897692.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7850</th>\n",
       "      <td>openb-pod-7850</td>\n",
       "      <td>6000</td>\n",
       "      <td>18432</td>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LS</td>\n",
       "      <td>Running</td>\n",
       "      <td>12898342</td>\n",
       "      <td>12900034</td>\n",
       "      <td>12898342.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7851</th>\n",
       "      <td>openb-pod-7851</td>\n",
       "      <td>3152</td>\n",
       "      <td>5600</td>\n",
       "      <td>1</td>\n",
       "      <td>590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BE</td>\n",
       "      <td>Failed</td>\n",
       "      <td>12900505</td>\n",
       "      <td>12900526</td>\n",
       "      <td>12900505.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7852</th>\n",
       "      <td>openb-pod-7852</td>\n",
       "      <td>3152</td>\n",
       "      <td>5600</td>\n",
       "      <td>1</td>\n",
       "      <td>590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BE</td>\n",
       "      <td>Failed</td>\n",
       "      <td>12901761</td>\n",
       "      <td>12901792</td>\n",
       "      <td>12901762.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7853 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                name  cpu_milli  memory_mib  num_gpu  gpu_milli  gpu_spec qos  \\\n",
       "0     openb-pod-0000      12500       57344        0          0       NaN  LS   \n",
       "1     openb-pod-0001      12500       57344        0          0       NaN  LS   \n",
       "2     openb-pod-0002      32000       49152        0          0       NaN  BE   \n",
       "3     openb-pod-0003      16500       51200        0          0       NaN  LS   \n",
       "4     openb-pod-0004       8000       30517        0          0       NaN  BE   \n",
       "...              ...        ...         ...      ...        ...       ...  ..   \n",
       "7848  openb-pod-7848      16000       32768        1       1000       NaN  LS   \n",
       "7849  openb-pod-7849      11400       77824        1       1000       NaN  LS   \n",
       "7850  openb-pod-7850       6000       18432        1        460       NaN  LS   \n",
       "7851  openb-pod-7851       3152        5600        1        590       NaN  BE   \n",
       "7852  openb-pod-7852       3152        5600        1        590       NaN  BE   \n",
       "\n",
       "      pod_phase  creation_time  deletion_time  scheduled_time  \n",
       "0       Running       10644355       10644932      10644358.0  \n",
       "1       Running       11556813       11557292      11556817.0  \n",
       "2       Running       11412186       11412330      11412189.0  \n",
       "3       Running       12524063       12524844      12524064.0  \n",
       "4       Running       10741000       10744539      10741002.0  \n",
       "...         ...            ...            ...             ...  \n",
       "7848  Succeeded       12897160       12900786      12897161.0  \n",
       "7849    Running       12897659       12898203      12897692.0  \n",
       "7850    Running       12898342       12900034      12898342.0  \n",
       "7851     Failed       12900505       12900526      12900505.0  \n",
       "7852     Failed       12901761       12901792      12901762.0  \n",
       "\n",
       "[7853 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv( 'cluster-trace-gpu-v2023/csv/openb_pod_list_cpu100.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last 40 predictions (EWA over heterogeneous experts, scaled):\n",
      "01  Actual= 3152.00  Predicted= 3290.87\n",
      "02  Actual=11400.00  Predicted=11613.40\n",
      "03  Actual=11400.00  Predicted=11693.60\n",
      "04  Actual= 8000.00  Predicted= 7929.64\n",
      "05  Actual=11400.00  Predicted=11580.05\n",
      "06  Actual= 3152.00  Predicted= 3120.45\n",
      "07  Actual=11908.00  Predicted=11903.56\n",
      "08  Actual=11908.00  Predicted=11911.12\n",
      "09  Actual= 8000.00  Predicted= 6404.24\n",
      "10  Actual=11908.00  Predicted=11909.46\n",
      "11  Actual=11908.00  Predicted=11953.72\n",
      "12  Actual=11908.00  Predicted=11911.88\n",
      "13  Actual=11400.00  Predicted=11653.00\n",
      "14  Actual= 8000.00  Predicted= 7954.48\n",
      "15  Actual=11908.00  Predicted=11884.18\n",
      "16  Actual=11908.00  Predicted=11904.79\n",
      "17  Actual=11908.00  Predicted=11899.60\n",
      "18  Actual=11908.00  Predicted=11915.43\n",
      "19  Actual=11908.00  Predicted=11909.79\n",
      "20  Actual= 3152.00  Predicted= 3105.31\n",
      "21  Actual=11908.00  Predicted=11909.86\n",
      "22  Actual=11908.00  Predicted=11909.92\n",
      "23  Actual= 3152.00  Predicted= 3099.63\n",
      "24  Actual= 3152.00  Predicted= 3107.84\n",
      "25  Actual=16000.00  Predicted= 9576.26\n",
      "26  Actual=24200.00  Predicted=24109.15\n",
      "27  Actual=11908.00  Predicted=11964.69\n",
      "28  Actual=11908.00  Predicted=11864.73\n",
      "29  Actual=12000.00  Predicted= 7687.82\n",
      "30  Actual= 8000.00  Predicted= 7941.62\n",
      "31  Actual=11908.00  Predicted=11900.07\n",
      "32  Actual= 4000.00  Predicted= 3972.84\n",
      "33  Actual=11400.00  Predicted=11675.84\n",
      "34  Actual= 3152.00  Predicted= 3195.51\n",
      "35  Actual= 3152.00  Predicted= 3107.40\n",
      "36  Actual=16000.00  Predicted=10111.30\n",
      "37  Actual=11400.00  Predicted=11618.21\n",
      "38  Actual= 6000.00  Predicted= 6058.57\n",
      "39  Actual= 3152.00  Predicted= 3132.94\n",
      "40  Actual= 3152.00  Predicted= 3112.62\n",
      "\n",
      "MAE=1254.03\n",
      "MAPE=16.61%\n",
      "WAPE=12.27%\n",
      "\n",
      "Final EWA weights:\n",
      "  bag_ht  : 0.025\n",
      "  hat     : 0.016\n",
      "  lin     : 0.005\n",
      "  knn     : 0.955\n",
      "\n",
      "SLA violations: 241  (rate = 0.031)\n",
      "Over-provisioned capacity (mCPU): 35407496.00\n",
      "Scaling actions taken: 3791\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "\n",
    "from river import (\n",
    "    ensemble, tree, preprocessing as pp, stream, metrics,\n",
    "    linear_model, neighbors, optim, utils\n",
    ")\n",
    "\n",
    "\n",
    "# Save / Load helpers\n",
    "def save_model(model, path):\n",
    "    utils.dump(model, path)\n",
    "    print(f\"Model saved to → {path}\")\n",
    "\n",
    "def load_model(path):\n",
    "    if os.path.exists(path):\n",
    "        model = utils.load(path)\n",
    "        print(f\"Model loaded from → {path}\")\n",
    "        return model\n",
    "    return None\n",
    "\n",
    "\n",
    "# Data\n",
    "CSV_PATH = 'cluster-trace-gpu-v2023/csv/openb_pod_list_cpu100.csv'\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Feature builder\n",
    "def build_features(df: pd.DataFrame):\n",
    "    df = df.copy()\n",
    "\n",
    "    num_cols = ['cpu_milli','memory_mib','num_gpu','gpu_milli',\n",
    "                'creation_time','deletion_time','scheduled_time']\n",
    "    for c in num_cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "        else:\n",
    "            df[c] = 0.0\n",
    "\n",
    "    y = df['cpu_milli'].fillna(0).astype(float)\n",
    "\n",
    "    X = pd.DataFrame(index=df.index)\n",
    "    X['mem_gib'] = (df['memory_mib'].fillna(0) / 1024.0).astype(float)\n",
    "    X['num_gpu'] = df['num_gpu'].fillna(0).astype(float)\n",
    "    X['gpu_milli'] = df['gpu_milli'].fillna(0).astype(float)\n",
    "\n",
    "    ct = df['creation_time'].fillna(0).astype(float)\n",
    "    dt = df['deletion_time'].fillna(0).astype(float)\n",
    "    st = df['scheduled_time'].fillna(0).astype(float)\n",
    "    X['lifetime']   = (dt - ct).clip(lower=0.0)\n",
    "    X['sched_delay'] = (st - ct).clip(lower=0.0)\n",
    "\n",
    "    X['has_gpu'] = (X['num_gpu'] > 0).astype(float)\n",
    "\n",
    "    qos = df.get('qos', '').astype(str).str.upper()\n",
    "    X['qos_LS'] = (qos == 'LS').astype(float)\n",
    "    X['qos_BE'] = (qos == 'BE').astype(float)\n",
    "\n",
    "    phase = df.get('pod_phase', '').astype(str).str.title()\n",
    "    X['ph_Running']   = (phase == 'Running').astype(float)\n",
    "    X['ph_Succeeded'] = (phase == 'Succeeded').astype(float)\n",
    "    X['ph_Failed']    = (phase == 'Failed').astype(float)\n",
    "\n",
    "    X = X.replace([np.inf, -np.inf], np.nan).fillna(0.0).astype(float)\n",
    "    features = list(X.columns)\n",
    "    return X, y, features\n",
    "\n",
    "X, y, features = build_features(df)\n",
    "\n",
    "# Models (experts)\n",
    "def make_bag_ht():\n",
    "    return ensemble.BaggingRegressor(\n",
    "        model=tree.HoeffdingTreeRegressor(\n",
    "            grace_period=100,\n",
    "            max_depth=20,\n",
    "            leaf_prediction='mean'\n",
    "        ),\n",
    "        n_models=20,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "def make_hat():\n",
    "    return tree.HoeffdingAdaptiveTreeRegressor(\n",
    "        grace_period=100,\n",
    "        leaf_prediction='mean'\n",
    "    )\n",
    "\n",
    "def make_lin():\n",
    "    return pp.StandardScaler() | linear_model.PARegressor()\n",
    "\n",
    "def make_knn():\n",
    "    engine = neighbors.LazySearch(\n",
    "        window_size=3000, \n",
    "        min_distance_keep=0.0  \n",
    "    )\n",
    "    return pp.StandardScaler() | neighbors.KNNRegressor(\n",
    "        n_neighbors=30,\n",
    "        engine=engine,\n",
    "        aggregation_method=\"mean\"  \n",
    "    )\n",
    "\n",
    "experts = [make_bag_ht(), make_hat(), make_lin(), make_knn()]\n",
    "\n",
    "# EWA over experts\n",
    "ewa = ensemble.EWARegressor(models=experts, loss=optim.losses.Squared(), learning_rate=2e-3)\n",
    "\n",
    "# Metrics\n",
    "mae = metrics.MAE()\n",
    "\n",
    "class OnlineMAPE:\n",
    "    def __init__(self, eps=1e-8):\n",
    "        self.eps = eps\n",
    "        self.n = 0\n",
    "        self.sum_pe = 0.0\n",
    "    def update(self, y_true, y_pred):\n",
    "        y_true = float(y_true); y_pred = float(y_pred)\n",
    "        pe = abs(y_true - y_pred) / max(self.eps, abs(y_true))\n",
    "        self.sum_pe += pe\n",
    "        self.n += 1\n",
    "    def get(self):\n",
    "        return (self.sum_pe / max(1, self.n)) * 100.0\n",
    "\n",
    "class OnlineWAPE:\n",
    "    def __init__(self, eps=1e-8):\n",
    "        self.eps = eps\n",
    "        self.sum_abs_err = 0.0\n",
    "        self.sum_abs_true = 0.0\n",
    "    def update(self, y_true, y_pred):\n",
    "        self.sum_abs_err += abs(float(y_true) - float(y_pred))\n",
    "        self.sum_abs_true += abs(float(y_true))\n",
    "    def get(self):\n",
    "        return 100.0 * self.sum_abs_err / max(self.eps, self.sum_abs_true)\n",
    "\n",
    "mape, wape = OnlineMAPE(), OnlineWAPE()\n",
    "\n",
    "# Scaling and loop settings\n",
    "TARGET_SCALE = float(np.percentile(np.abs(y.values), 75))\n",
    "TARGET_SCALE = max(1.0, TARGET_SCALE)\n",
    "\n",
    "last_preds = deque(maxlen=40)\n",
    "WARM_UP = 200\n",
    "SEEN = 0\n",
    "\n",
    "NODE_CAPACITY = 8000  \n",
    "sla_violations = 0\n",
    "overprov = 0.0\n",
    "scaling_actions = 0\n",
    "current_nodes = 1\n",
    "\n",
    "# Online loop\n",
    "for x_row, y_true in stream.iter_pandas(X[features], y):\n",
    "    SEEN += 1\n",
    "\n",
    "    # Predict\n",
    "    if SEEN <= WARM_UP:\n",
    "        preds = [(m.predict_one(x_row) or 0.0) for m in experts]\n",
    "        y_hat_scaled = float(np.mean(preds)) if preds else 0.0\n",
    "    else:\n",
    "        y_hat_scaled = ewa.predict_one(x_row) or 0.0\n",
    "\n",
    "    # Rescale to original target and clip negatives\n",
    "    y_hat = max(0.0, y_hat_scaled * TARGET_SCALE)\n",
    "\n",
    "    # Metrics\n",
    "    mae.update(y_true, y_hat)\n",
    "    mape.update(y_true, y_hat)\n",
    "    wape.update(y_true, y_hat)\n",
    "\n",
    "    # Autoscaling policy\n",
    "    needed_nodes = max(1, int(np.ceil(y_hat / NODE_CAPACITY)))\n",
    "    if needed_nodes * NODE_CAPACITY < float(y_true):\n",
    "        sla_violations += 1\n",
    "    overprov += max(0.0, needed_nodes * NODE_CAPACITY - float(y_true))\n",
    "    if needed_nodes != current_nodes:\n",
    "        scaling_actions += 1\n",
    "        current_nodes = needed_nodes\n",
    "\n",
    "    # Train (scale target for stability)\n",
    "    y_scaled = float(y_true) / TARGET_SCALE\n",
    "    for m in experts:\n",
    "        m.learn_one(x_row, y_scaled)\n",
    "    if SEEN > WARM_UP:\n",
    "        ewa.learn_one(x_row, y_scaled)\n",
    "\n",
    "    last_preds.append((float(y_true), float(y_hat)))\n",
    "\n",
    "# Report\n",
    "print(\"Last 40 predictions (EWA over heterogeneous experts, scaled):\")\n",
    "for i, (yt, yh) in enumerate(last_preds, 1):\n",
    "    print(f\"{i:02d}  Actual={yt:8.2f}  Predicted={yh:8.2f}\")\n",
    "\n",
    "print(f\"\\nMAE={mae.get():.2f}\")\n",
    "print(f\"MAPE={mape.get():.2f}%\")\n",
    "print(f\"WAPE={wape.get():.2f}%\")\n",
    "\n",
    "if hasattr(ewa, \"weights\"):\n",
    "    print(\"\\nFinal EWA weights:\")\n",
    "    for name, w in zip([\"bag_ht\",\"hat\",\"lin\",\"knn\"], ewa.weights):\n",
    "        print(f\"  {name:8s}: {w:.3f}\")\n",
    "\n",
    "total_steps = max(1, SEEN)\n",
    "sla_violation_rate = sla_violations / total_steps\n",
    "print(f\"\\nSLA violations: {sla_violations}  (rate = {sla_violation_rate:.3f})\")\n",
    "print(f\"Over-provisioned capacity (mCPU): {overprov:.2f}\")\n",
    "print(f\"Scaling actions taken: {scaling_actions}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Naive-LAST ===\n",
      "Last 40 predictions:\n",
      "01  Actual=11400.00  Predicted= 3152.00\n",
      "02  Actual=11400.00  Predicted=11400.00\n",
      "03  Actual=32000.00  Predicted=11400.00\n",
      "04  Actual= 8000.00  Predicted=32000.00\n",
      "05  Actual=11400.00  Predicted= 8000.00\n",
      "06  Actual= 3152.00  Predicted=11400.00\n",
      "07  Actual=11908.00  Predicted= 3152.00\n",
      "08  Actual=11908.00  Predicted=11908.00\n",
      "09  Actual= 8000.00  Predicted=11908.00\n",
      "10  Actual=11908.00  Predicted= 8000.00\n",
      "11  Actual=11908.00  Predicted=11908.00\n",
      "12  Actual=11908.00  Predicted=11908.00\n",
      "13  Actual=11400.00  Predicted=11908.00\n",
      "14  Actual= 8000.00  Predicted=11400.00\n",
      "15  Actual=11908.00  Predicted= 8000.00\n",
      "16  Actual=11908.00  Predicted=11908.00\n",
      "17  Actual=11908.00  Predicted=11908.00\n",
      "18  Actual=11908.00  Predicted=11908.00\n",
      "19  Actual=11908.00  Predicted=11908.00\n",
      "20  Actual= 3152.00  Predicted=11908.00\n",
      "21  Actual=11908.00  Predicted= 3152.00\n",
      "22  Actual=11908.00  Predicted=11908.00\n",
      "23  Actual= 3152.00  Predicted=11908.00\n",
      "24  Actual= 3152.00  Predicted= 3152.00\n",
      "25  Actual=16000.00  Predicted= 3152.00\n",
      "26  Actual=24200.00  Predicted=16000.00\n",
      "27  Actual=11908.00  Predicted=24200.00\n",
      "28  Actual=11908.00  Predicted=11908.00\n",
      "29  Actual=12000.00  Predicted=11908.00\n",
      "30  Actual= 8000.00  Predicted=12000.00\n",
      "31  Actual=11908.00  Predicted= 8000.00\n",
      "32  Actual= 4000.00  Predicted=11908.00\n",
      "33  Actual=11400.00  Predicted= 4000.00\n",
      "34  Actual= 3152.00  Predicted=11400.00\n",
      "35  Actual= 3152.00  Predicted= 3152.00\n",
      "36  Actual=16000.00  Predicted= 3152.00\n",
      "37  Actual=11400.00  Predicted=16000.00\n",
      "38  Actual= 6000.00  Predicted=11400.00\n",
      "39  Actual= 3152.00  Predicted= 6000.00\n",
      "40  Actual= 3152.00  Predicted= 3152.00\n",
      "\n",
      "MAE=5693.59\n",
      "MAPE=83.41%\n",
      "WAPE=55.69%\n",
      "SLA violations: 1798  (rate=0.229)\n",
      "Over-provision (raw mCPU): 43045000.00\n",
      "Over-provision RATE: 53.61%\n",
      "Scaling actions taken: 3618\n",
      "\n",
      "=== MovingAverage-30 ===\n",
      "Last 40 predictions:\n",
      "01  Actual=11400.00  Predicted= 9353.20\n",
      "02  Actual=11400.00  Predicted= 9186.53\n",
      "03  Actual=32000.00  Predicted= 9169.60\n",
      "04  Actual= 8000.00  Predicted= 9839.33\n",
      "05  Actual=11400.00  Predicted= 9839.33\n",
      "06  Actual= 3152.00  Predicted=10114.27\n",
      "07  Actual=11908.00  Predicted=10114.27\n",
      "08  Actual=11908.00  Predicted=10406.13\n",
      "09  Actual= 8000.00  Predicted=10406.13\n",
      "10  Actual=11908.00  Predicted=10275.87\n",
      "11  Actual=11908.00  Predicted=10567.73\n",
      "12  Actual=11908.00  Predicted=10567.73\n",
      "13  Actual=11400.00  Predicted=10859.60\n",
      "14  Actual= 8000.00  Predicted=11134.53\n",
      "15  Actual=11908.00  Predicted=11004.27\n",
      "16  Actual=11908.00  Predicted=11004.27\n",
      "17  Actual=11908.00  Predicted=11296.13\n",
      "18  Actual=11908.00  Predicted=11146.40\n",
      "19  Actual=11908.00  Predicted=11438.27\n",
      "20  Actual= 3152.00  Predicted=11730.13\n",
      "21  Actual=11908.00  Predicted=11730.13\n",
      "22  Actual=11908.00  Predicted=11730.13\n",
      "23  Actual= 3152.00  Predicted=11730.13\n",
      "24  Actual= 3152.00  Predicted=11701.87\n",
      "25  Actual=16000.00  Predicted=11673.60\n",
      "26  Actual=24200.00  Predicted=11140.27\n",
      "27  Actual=11908.00  Predicted=10880.27\n",
      "28  Actual=11908.00  Predicted=10897.20\n",
      "29  Actual=12000.00  Predicted=10914.13\n",
      "30  Actual= 8000.00  Predicted=11209.07\n",
      "31  Actual=11908.00  Predicted=11370.67\n",
      "32  Actual= 4000.00  Predicted=11387.60\n",
      "33  Actual=11400.00  Predicted=11140.93\n",
      "34  Actual= 3152.00  Predicted=10454.27\n",
      "35  Actual= 3152.00  Predicted=10292.67\n",
      "36  Actual=16000.00  Predicted=10017.73\n",
      "37  Actual=11400.00  Predicted=10446.00\n",
      "38  Actual= 6000.00  Predicted=10429.07\n",
      "39  Actual= 3152.00  Predicted=10232.13\n",
      "40  Actual= 3152.00  Predicted=10070.53\n",
      "\n",
      "MAE=4938.67\n",
      "MAPE=79.08%\n",
      "WAPE=48.30%\n",
      "SLA violations: 1207  (rate=0.154)\n",
      "Over-provision (raw mCPU): 44676484.00\n",
      "Over-provision RATE: 55.64%\n",
      "Scaling actions taken: 233\n",
      "\n",
      "=== HoltWinters(trend=add) ===\n",
      "Last 40 predictions:\n",
      "01  Actual=11400.00  Predicted= 8855.42\n",
      "02  Actual=11400.00  Predicted= 8855.42\n",
      "03  Actual=32000.00  Predicted= 8855.42\n",
      "04  Actual= 8000.00  Predicted= 8855.42\n",
      "05  Actual=11400.00  Predicted= 8855.42\n",
      "06  Actual= 3152.00  Predicted= 8855.42\n",
      "07  Actual=11908.00  Predicted= 8855.42\n",
      "08  Actual=11908.00  Predicted= 8855.42\n",
      "09  Actual= 8000.00  Predicted= 8855.42\n",
      "10  Actual=11908.00  Predicted= 8855.42\n",
      "11  Actual=11908.00  Predicted= 8855.42\n",
      "12  Actual=11908.00  Predicted= 8855.42\n",
      "13  Actual=11400.00  Predicted= 8855.42\n",
      "14  Actual= 8000.00  Predicted= 8855.42\n",
      "15  Actual=11908.00  Predicted= 8855.42\n",
      "16  Actual=11908.00  Predicted= 8855.42\n",
      "17  Actual=11908.00  Predicted= 8855.42\n",
      "18  Actual=11908.00  Predicted= 8855.42\n",
      "19  Actual=11908.00  Predicted= 8855.42\n",
      "20  Actual= 3152.00  Predicted= 8855.42\n",
      "21  Actual=11908.00  Predicted= 8855.42\n",
      "22  Actual=11908.00  Predicted= 8855.42\n",
      "23  Actual= 3152.00  Predicted= 8855.42\n",
      "24  Actual= 3152.00  Predicted= 8855.42\n",
      "25  Actual=16000.00  Predicted= 8855.42\n",
      "26  Actual=24200.00  Predicted= 8855.42\n",
      "27  Actual=11908.00  Predicted= 8855.42\n",
      "28  Actual=11908.00  Predicted= 8855.42\n",
      "29  Actual=12000.00  Predicted= 8855.42\n",
      "30  Actual= 8000.00  Predicted= 8855.42\n",
      "31  Actual=11908.00  Predicted= 8855.42\n",
      "32  Actual= 4000.00  Predicted= 8855.42\n",
      "33  Actual=11400.00  Predicted= 8855.42\n",
      "34  Actual= 3152.00  Predicted= 8855.42\n",
      "35  Actual= 3152.00  Predicted= 8855.42\n",
      "36  Actual=16000.00  Predicted= 8855.42\n",
      "37  Actual=11400.00  Predicted= 8855.42\n",
      "38  Actual= 6000.00  Predicted= 8855.42\n",
      "39  Actual= 3152.00  Predicted= 8855.42\n",
      "40  Actual= 3152.00  Predicted= 8855.42\n",
      "\n",
      "MAE=4931.46\n",
      "MAPE=80.98%\n",
      "WAPE=48.23%\n",
      "SLA violations: 972  (rate=0.124)\n",
      "Over-provision (raw mCPU): 48873530.00\n",
      "Over-provision RATE: 60.87%\n",
      "Scaling actions taken: 218\n",
      "\n",
      "=== SARIMA(1,1,1) ===\n",
      "Last 40 predictions:\n",
      "01  Actual=11400.00  Predicted= 9013.48\n",
      "02  Actual=11400.00  Predicted= 9013.48\n",
      "03  Actual=32000.00  Predicted= 9013.48\n",
      "04  Actual= 8000.00  Predicted= 9013.48\n",
      "05  Actual=11400.00  Predicted= 9013.48\n",
      "06  Actual= 3152.00  Predicted= 9013.48\n",
      "07  Actual=11908.00  Predicted= 9013.48\n",
      "08  Actual=11908.00  Predicted= 9013.48\n",
      "09  Actual= 8000.00  Predicted= 9013.48\n",
      "10  Actual=11908.00  Predicted= 9013.48\n",
      "11  Actual=11908.00  Predicted= 9013.48\n",
      "12  Actual=11908.00  Predicted= 9013.48\n",
      "13  Actual=11400.00  Predicted= 9013.48\n",
      "14  Actual= 8000.00  Predicted= 9013.48\n",
      "15  Actual=11908.00  Predicted= 9013.48\n",
      "16  Actual=11908.00  Predicted= 9013.48\n",
      "17  Actual=11908.00  Predicted= 9013.48\n",
      "18  Actual=11908.00  Predicted= 9013.48\n",
      "19  Actual=11908.00  Predicted= 9013.48\n",
      "20  Actual= 3152.00  Predicted= 9013.48\n",
      "21  Actual=11908.00  Predicted= 9013.48\n",
      "22  Actual=11908.00  Predicted= 9013.48\n",
      "23  Actual= 3152.00  Predicted= 9013.48\n",
      "24  Actual= 3152.00  Predicted= 9013.48\n",
      "25  Actual=16000.00  Predicted= 9013.48\n",
      "26  Actual=24200.00  Predicted= 9013.48\n",
      "27  Actual=11908.00  Predicted= 9013.48\n",
      "28  Actual=11908.00  Predicted= 9013.48\n",
      "29  Actual=12000.00  Predicted= 9013.48\n",
      "30  Actual= 8000.00  Predicted= 9013.48\n",
      "31  Actual=11908.00  Predicted= 9013.48\n",
      "32  Actual= 4000.00  Predicted= 9013.48\n",
      "33  Actual=11400.00  Predicted= 9013.48\n",
      "34  Actual= 3152.00  Predicted= 9013.48\n",
      "35  Actual= 3152.00  Predicted= 9013.48\n",
      "36  Actual=16000.00  Predicted= 9013.48\n",
      "37  Actual=11400.00  Predicted= 9013.48\n",
      "38  Actual= 6000.00  Predicted= 9013.48\n",
      "39  Actual= 3152.00  Predicted= 9013.48\n",
      "40  Actual= 3152.00  Predicted= 9013.48\n",
      "\n",
      "MAE=4937.58\n",
      "MAPE=80.40%\n",
      "WAPE=48.29%\n",
      "SLA violations: 1191  (rate=0.152)\n",
      "Over-provision (raw mCPU): 47645494.00\n",
      "Over-provision RATE: 59.34%\n",
      "Scaling actions taken: 220\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "\n",
    "from statsmodels.tsa.api import ExponentialSmoothing, SARIMAX\n",
    "\n",
    "\n",
    "CSV_PATH = 'cluster-trace-gpu-v2023/csv/openb_pod_list_cpu100.csv'\n",
    "\n",
    "NODE_CAPACITY = 8000  \n",
    "\n",
    "INIT_WINDOW = 500     \n",
    "REFIT_EVERY = 250     \n",
    "CLIP_NEGATIVE = True    \n",
    "\n",
    "class MAE:\n",
    "    def __init__(self): self.err = 0.0; self.n = 0\n",
    "    def update(self, y, yhat):\n",
    "        self.err += abs(float(y) - float(yhat)); self.n += 1\n",
    "    def get(self): return self.err / max(1, self.n)\n",
    "\n",
    "class OnlineMAPE:\n",
    "    def __init__(self, eps=1e-8): self.eps=eps; self.n=0; self.sum_pe=0.0\n",
    "    def update(self, y, yhat):\n",
    "        y = float(y); yhat = float(yhat)\n",
    "        pe = abs(y - yhat) / max(self.eps, abs(y))\n",
    "        self.sum_pe += pe; self.n += 1\n",
    "    def get(self): return 100.0 * self.sum_pe / max(1, self.n)\n",
    "\n",
    "class OnlineWAPE:\n",
    "    def __init__(self, eps=1e-8): self.eps=eps; self.sae=0.0; self.sat=0.0\n",
    "    def update(self, y, yhat):\n",
    "        self.sae += abs(float(y)-float(yhat))\n",
    "        self.sat += abs(float(y))\n",
    "    def get(self): return 100.0 * self.sae / max(self.eps, self.sat)\n",
    "\n",
    "def autoscale_metrics(y_true_seq, y_hat_seq, node_capacity=NODE_CAPACITY):\n",
    "    \"\"\"\n",
    "    Compute SLA violations, Over-Provision (raw and normalized), Scaling actions.\n",
    "    \"\"\"\n",
    "    sla_violations = 0\n",
    "    overprov_raw = 0.0\n",
    "    scaling_actions = 0\n",
    "    current_nodes = 1\n",
    "\n",
    "    for y_true, y_hat in zip(y_true_seq, y_hat_seq):\n",
    "        needed_nodes = max(1, int(np.ceil(float(y_hat) / node_capacity)))\n",
    "        if needed_nodes * node_capacity < float(y_true):\n",
    "            sla_violations += 1\n",
    "        overprov_raw += max(0.0, needed_nodes * node_capacity - float(y_true))\n",
    "        if needed_nodes != current_nodes:\n",
    "            scaling_actions += 1\n",
    "            current_nodes = needed_nodes\n",
    "\n",
    "    total = len(y_true_seq)\n",
    "    sla_rate = sla_violations / max(1, total)\n",
    "    denom = sum(map(float, y_true_seq)) + 1e-8\n",
    "    overprov_rate = overprov_raw / denom\n",
    "\n",
    "    return dict(\n",
    "        sla_violations=sla_violations,\n",
    "        sla_rate=sla_rate,\n",
    "        overprov_raw=overprov_raw,\n",
    "        overprov_rate=overprov_rate,\n",
    "        scaling_actions=scaling_actions\n",
    "    )\n",
    "\n",
    "def load_ordered_series(csv_path=CSV_PATH):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if 'creation_time' not in df.columns:\n",
    "        raise ValueError(\"creation_time column is required for proper time ordering.\")\n",
    "\n",
    "    df['creation_time'] = pd.to_numeric(df['creation_time'], errors='coerce').fillna(0).astype(float)\n",
    "    df['cpu_milli'] = pd.to_numeric(df['cpu_milli'], errors='coerce').fillna(0).astype(float)\n",
    "\n",
    "    df = df.sort_values('creation_time').reset_index(drop=True)\n",
    "    y = df['cpu_milli'].astype(float).values \n",
    "    return y, df\n",
    "def baseline_naive_last(y):\n",
    "    preds = []\n",
    "    last = y[0]\n",
    "    for t in range(len(y)):\n",
    "        if t < 1:\n",
    "            preds.append(y[0])  \n",
    "        else:\n",
    "            preds.append(last)\n",
    "        last = y[t]\n",
    "    return np.array(preds, dtype=float)\n",
    "\n",
    "def baseline_moving_average(y, window=20):\n",
    "    preds = []\n",
    "    csum = 0.0\n",
    "    buf = []\n",
    "    for t in range(len(y)):\n",
    "        if t < 1:\n",
    "            preds.append(y[0])\n",
    "        else:\n",
    "            w = min(window, len(buf))\n",
    "            mean = np.mean(buf[-w:]) if w > 0 else y[t-1]\n",
    "            preds.append(mean)\n",
    "        buf.append(y[t])\n",
    "    return np.array(preds, dtype=float)\n",
    "\n",
    "def baseline_holt_winters(y, trend='add', seasonal=None, seasonal_periods=None):\n",
    "\n",
    "    n = len(y)\n",
    "    preds = np.zeros(n, dtype=float)\n",
    "    preds[:INIT_WINDOW] = baseline_naive_last(y)[:INIT_WINDOW]\n",
    "\n",
    "    last_refit = INIT_WINDOW\n",
    "    model = None\n",
    "    fit = None\n",
    "\n",
    "    for t in range(INIT_WINDOW, n):\n",
    "        if (t - last_refit) >= REFIT_EVERY or fit is None:\n",
    "            model = ExponentialSmoothing(\n",
    "                y[:t],\n",
    "                trend=trend,\n",
    "                seasonal=seasonal,\n",
    "                seasonal_periods=seasonal_periods,\n",
    "                initialization_method=\"estimated\"\n",
    "            )\n",
    "            fit = model.fit(optimized=True, use_brute=False)\n",
    "            last_refit = t\n",
    "        preds[t] = float(fit.forecast(1)[0])\n",
    "    return preds\n",
    "\n",
    "def baseline_sarima(y, order=(1,1,1), seasonal_order=(0,0,0,0)):\n",
    "    n = len(y)\n",
    "    preds = np.zeros(n, dtype=float)\n",
    "    preds[:INIT_WINDOW] = baseline_naive_last(y)[:INIT_WINDOW]\n",
    "\n",
    "    last_refit = INIT_WINDOW\n",
    "    fit = None\n",
    "\n",
    "    for t in range(INIT_WINDOW, n):\n",
    "        if (t - last_refit) >= REFIT_EVERY or fit is None:\n",
    "            try:\n",
    "                model = SARIMAX(\n",
    "                    y[:t],\n",
    "                    order=order,\n",
    "                    seasonal_order=seasonal_order,\n",
    "                    enforce_stationarity=False,\n",
    "                    enforce_invertibility=False\n",
    "                )\n",
    "                fit = model.fit(disp=False)\n",
    "                last_refit = t\n",
    "            except Exception as e:\n",
    "                fit = None\n",
    "        if fit is not None:\n",
    "            try:\n",
    "                preds[t] = float(fit.forecast(1)[0])\n",
    "            except Exception:\n",
    "                preds[t] = y[t-1]\n",
    "        else:\n",
    "            preds[t] = y[t-1]\n",
    "    return preds\n",
    "\n",
    "def evaluate_forecasts(y_true, y_hat, name=\"MODEL\"):\n",
    "    if CLIP_NEGATIVE:\n",
    "        y_hat = np.maximum(0.0, y_hat)\n",
    "\n",
    "    last_preds = deque(maxlen=40)\n",
    "    mae = MAE(); mape = OnlineMAPE(); wape = OnlineWAPE()\n",
    "\n",
    "    for yt, yh in zip(y_true, y_hat):\n",
    "        mae.update(yt, yh); mape.update(yt, yh); wape.update(yt, yh)\n",
    "        last_preds.append((float(yt), float(yh)))\n",
    "\n",
    "    auto = autoscale_metrics(y_true, y_hat, node_capacity=NODE_CAPACITY)\n",
    "\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(\"Last 40 predictions:\")\n",
    "    for i, (yt, yh) in enumerate(last_preds, 1):\n",
    "        print(f\"{i:02d}  Actual={yt:8.2f}  Predicted={yh:8.2f}\")\n",
    "\n",
    "    print(f\"\\nMAE={mae.get():.2f}\")\n",
    "    print(f\"MAPE={mape.get():.2f}%\")\n",
    "    print(f\"WAPE={wape.get():.2f}%\")\n",
    "    print(f\"SLA violations: {auto['sla_violations']}  (rate={auto['sla_rate']:.3f})\")\n",
    "    print(f\"Over-provision (raw mCPU): {auto['overprov_raw']:.2f}\")\n",
    "    print(f\"Over-provision RATE: {100.0*auto['overprov_rate']:.2f}%\")\n",
    "    print(f\"Scaling actions taken: {auto['scaling_actions']}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    y, df = load_ordered_series(CSV_PATH)\n",
    "\n",
    "    yhat_naive = baseline_naive_last(y)\n",
    "    evaluate_forecasts(y, yhat_naive, name=\"Naive-LAST\")\n",
    "\n",
    "    yhat_ma = baseline_moving_average(y, window=30)\n",
    "    evaluate_forecasts(y, yhat_ma, name=\"MovingAverage-30\")\n",
    "\n",
    "    yhat_hw = baseline_holt_winters(y, trend=\"add\", seasonal=None, seasonal_periods=None)\n",
    "    evaluate_forecasts(y, yhat_hw, name=\"HoltWinters(trend=add)\")\n",
    "    yhat_arima = baseline_sarima(y, order=(1,1,1), seasonal_order=(0,0,0,0))\n",
    "    evaluate_forecasts(y, yhat_arima, name=\"SARIMA(1,1,1)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binned series length = 7225 (per_sync_ms=10000, agg=max)\n",
      "\n",
      "=== PHPA Linear (lookAhead=10000ms, hist=24) (PHPA-like) ===\n",
      "Last 40 predictions:\n",
      "01  Actual= 4000.00  Predicted= 8539.62\n",
      "02  Actual=32000.00  Predicted= 7631.10\n",
      "03  Actual=11400.00  Predicted=11309.36\n",
      "04  Actual=11400.00  Predicted=11240.72\n",
      "05  Actual= 3152.00  Predicted=11162.32\n",
      "06  Actual=11400.00  Predicted=10796.93\n",
      "07  Actual=11400.00  Predicted=11527.04\n",
      "08  Actual=32000.00  Predicted=11894.54\n",
      "09  Actual= 8000.00  Predicted=15201.71\n",
      "10  Actual=11400.00  Predicted=14195.32\n",
      "11  Actual= 3152.00  Predicted=13702.90\n",
      "12  Actual=11908.00  Predicted=12571.00\n",
      "13  Actual= 8000.00  Predicted=12993.61\n",
      "14  Actual=11908.00  Predicted=12764.88\n",
      "15  Actual=11400.00  Predicted=12405.13\n",
      "16  Actual= 8000.00  Predicted=12690.38\n",
      "17  Actual=11908.00  Predicted=12414.48\n",
      "18  Actual=11908.00  Predicted=12007.55\n",
      "19  Actual=11908.00  Predicted=12753.45\n",
      "20  Actual=11908.00  Predicted=12300.17\n",
      "21  Actual=11908.00  Predicted=11751.72\n",
      "22  Actual= 3152.00  Predicted=11108.10\n",
      "23  Actual=11908.00  Predicted= 9734.81\n",
      "24  Actual= 3152.00  Predicted= 9916.03\n",
      "25  Actual= 3152.00  Predicted= 7892.96\n",
      "26  Actual=16000.00  Predicted= 5879.10\n",
      "27  Actual=24200.00  Predicted= 8653.48\n",
      "28  Actual=11908.00  Predicted=11027.86\n",
      "29  Actual=11908.00  Predicted=11214.43\n",
      "30  Actual=12000.00  Predicted=10618.51\n",
      "31  Actual= 8000.00  Predicted=10719.72\n",
      "32  Actual=11908.00  Predicted=10147.75\n",
      "33  Actual= 4000.00  Predicted=12204.65\n",
      "34  Actual=11400.00  Predicted=10901.07\n",
      "35  Actual= 3152.00  Predicted=11194.59\n",
      "36  Actual=16000.00  Predicted= 9336.46\n",
      "37  Actual=11400.00  Predicted=10444.51\n",
      "38  Actual= 6000.00  Predicted=10373.26\n",
      "39  Actual= 3152.00  Predicted= 9733.20\n",
      "40  Actual= 3152.00  Predicted= 8634.84\n",
      "\n",
      "MAE=5409.83\n",
      "MAPE=82.84%\n",
      "WAPE=53.01%\n",
      "SLA violations: 1439  (rate=0.199)\n",
      "Over-provision (raw mCPU): 40919338.00\n",
      "Over-provision RATE: 55.50%\n",
      "Scaling actions taken: 912\n",
      "\n",
      "=== Holt-Winters (trend-only) (PHPA-like) ===\n",
      "Last 40 predictions:\n",
      "01  Actual= 4000.00  Predicted= 7188.54\n",
      "02  Actual=32000.00  Predicted= 8157.14\n",
      "03  Actual=11400.00  Predicted= 9065.12\n",
      "04  Actual=11400.00  Predicted= 8623.20\n",
      "05  Actual= 3152.00  Predicted= 9077.02\n",
      "06  Actual=11400.00  Predicted= 7962.43\n",
      "07  Actual=11400.00  Predicted= 9189.91\n",
      "08  Actual=32000.00  Predicted= 8749.17\n",
      "09  Actual= 8000.00  Predicted= 8632.77\n",
      "10  Actual=11400.00  Predicted= 9971.79\n",
      "11  Actual= 3152.00  Predicted= 8931.02\n",
      "12  Actual=11908.00  Predicted= 8100.64\n",
      "13  Actual= 8000.00  Predicted= 8523.56\n",
      "14  Actual=11908.00  Predicted= 8897.51\n",
      "15  Actual=11400.00  Predicted= 8548.34\n",
      "16  Actual= 8000.00  Predicted= 8854.31\n",
      "17  Actual=11908.00  Predicted= 9346.86\n",
      "18  Actual=11908.00  Predicted= 9760.19\n",
      "19  Actual=11908.00  Predicted= 9777.07\n",
      "20  Actual=11908.00  Predicted= 9778.08\n",
      "21  Actual=11908.00  Predicted=10509.81\n",
      "22  Actual= 3152.00  Predicted=10100.30\n",
      "23  Actual=11908.00  Predicted= 9554.69\n",
      "24  Actual= 3152.00  Predicted=10259.24\n",
      "25  Actual= 3152.00  Predicted= 8471.78\n",
      "26  Actual=16000.00  Predicted= 8848.85\n",
      "27  Actual=24200.00  Predicted= 9000.90\n",
      "28  Actual=11908.00  Predicted=10583.32\n",
      "29  Actual=11908.00  Predicted= 9981.28\n",
      "30  Actual=12000.00  Predicted=10094.36\n",
      "31  Actual= 8000.00  Predicted=10068.38\n",
      "32  Actual=11908.00  Predicted=10242.55\n",
      "33  Actual= 4000.00  Predicted= 8843.03\n",
      "34  Actual=11400.00  Predicted= 9820.98\n",
      "35  Actual= 3152.00  Predicted=10102.62\n",
      "36  Actual=16000.00  Predicted= 9370.20\n",
      "37  Actual=11400.00  Predicted=10073.42\n",
      "38  Actual= 6000.00  Predicted=10711.96\n",
      "39  Actual= 3152.00  Predicted=10549.29\n",
      "40  Actual= 3152.00  Predicted= 9908.78\n",
      "\n",
      "MAE=4932.60\n",
      "MAPE=79.33%\n",
      "WAPE=48.34%\n",
      "SLA violations: 1095  (rate=0.152)\n",
      "Over-provision (raw mCPU): 42008370.00\n",
      "Over-provision RATE: 56.98%\n",
      "Scaling actions taken: 654\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "from statsmodels.tsa.api import ExponentialSmoothing\n",
    "CSV_PATH = 'cluster-trace-gpu-v2023/csv/openb_pod_list_cpu100.csv'\n",
    "\n",
    "NODE_CAPACITY = 8000        \n",
    "CLIP_NEGATIVE = True\n",
    "\n",
    "PER_SYNC_PERIOD_MS = 10_000\n",
    "BIN_AGG = 'max'              \n",
    "\n",
    "LOOKAHEAD_MS = 10_000      \n",
    "HISTORY_SIZE = 24          \n",
    "\n",
    "HW_TREND_ONLY = True     \n",
    "HW_SEASONAL = 'add'      \n",
    "HW_SEASONAL_PERIODS = 144   \n",
    "HW_STORED_SEASONS = 4    \n",
    "HW_MIN_WINDOW = 240          \n",
    "\n",
    "class MAE:\n",
    "    def __init__(self): self.err = 0.0; self.n = 0\n",
    "    def update(self, y, yhat):\n",
    "        self.err += abs(float(y) - float(yhat)); self.n += 1\n",
    "    def get(self): return self.err / max(1, self.n)\n",
    "\n",
    "class OnlineMAPE:\n",
    "    def __init__(self, eps=1e-8): self.eps=eps; self.n=0; self.sum_pe=0.0\n",
    "    def update(self, y, yhat):\n",
    "        y = float(y); yhat = float(yhat)\n",
    "        self.sum_pe += abs(y - yhat) / max(self.eps, abs(y)); self.n += 1\n",
    "    def get(self): return 100.0 * self.sum_pe / max(1, self.n)\n",
    "\n",
    "class OnlineWAPE:\n",
    "    def __init__(self, eps=1e-8): self.eps=eps; self.sae=0.0; self.sat=0.0\n",
    "    def update(self, y, yhat):\n",
    "        self.sae += abs(float(y)-float(yhat))\n",
    "        self.sat += abs(float(y))\n",
    "    def get(self): return 100.0 * self.sae / max(self.eps, self.sat)\n",
    "\n",
    "def autoscale_metrics(y_true_seq, y_hat_seq, node_capacity=NODE_CAPACITY):\n",
    "    sla_violations = 0\n",
    "    overprov_raw = 0.0\n",
    "    scaling_actions = 0\n",
    "    current_nodes = 1\n",
    "    for yt, yh in zip(y_true_seq, y_hat_seq):\n",
    "        need = max(1, int(np.ceil(float(yh)/node_capacity)))\n",
    "        if need*node_capacity < float(yt): sla_violations += 1\n",
    "        overprov_raw += max(0.0, need*node_capacity - float(yt))\n",
    "        if need != current_nodes:\n",
    "            scaling_actions += 1\n",
    "            current_nodes = need\n",
    "    total = len(y_true_seq)\n",
    "    sla_rate = sla_violations / max(1, total)\n",
    "    denom = float(np.sum(y_true_seq)) + 1e-8\n",
    "    overprov_rate = overprov_raw / denom\n",
    "    return dict(\n",
    "        sla_violations=sla_violations,\n",
    "        sla_rate=sla_rate,\n",
    "        overprov_raw=overprov_raw,\n",
    "        overprov_rate=overprov_rate,\n",
    "        scaling_actions=scaling_actions\n",
    "    )\n",
    "\n",
    "\n",
    "def _normalize_creation_time_to_ms(ct: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Heuristic: convert creation_time to milliseconds if needed.\"\"\"\n",
    "    ct = ct.astype(float)\n",
    "    mx = float(np.nanmax(ct)) if len(ct) else 0.0\n",
    "    if mx > 1e15:   ct = ct / 1e6  \n",
    "    elif mx > 1e12: ct = ct / 1e3   \n",
    "    elif mx < 1e9:  ct = ct * 1e3  \n",
    "    return ct\n",
    "\n",
    "def load_binned_series(csv_path=CSV_PATH, per_sync_ms=PER_SYNC_PERIOD_MS, how=BIN_AGG,\n",
    "                       filter_col=None, filter_val=None):\n",
    "    \"\"\"\n",
    "    Build a fixed-interval time series by binning creation_time into per_sync_ms buckets.\n",
    "    If filter_col & filter_val provided and column exists → filter rows first.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if 'creation_time' not in df.columns:\n",
    "        raise ValueError(\"creation_time column is required for binning.\")\n",
    "\n",
    "    df['cpu_milli'] = pd.to_numeric(df.get('cpu_milli', 0), errors='coerce')\n",
    "    df['creation_time'] = pd.to_numeric(df['creation_time'], errors='coerce')\n",
    "    df = df.dropna(subset=['creation_time', 'cpu_milli']).copy()\n",
    "\n",
    "    if filter_col and filter_col in df.columns:\n",
    "        df = df[df[filter_col] == filter_val].copy()\n",
    "\n",
    "    df['creation_time'] = _normalize_creation_time_to_ms(df['creation_time'].values)\n",
    "    df['creation_time'] = df['creation_time'].astype(np.int64)\n",
    "    df['bin'] = (df['creation_time'] // int(per_sync_ms)).astype(np.int64)\n",
    "\n",
    "    if how == 'max':\n",
    "        agg = df.groupby('bin', as_index=True)['cpu_milli'].max()\n",
    "    else:\n",
    "        agg = df.groupby('bin', as_index=True)['cpu_milli'].mean()\n",
    "\n",
    "    agg = agg.sort_index()\n",
    "    y = agg.values.astype(float)\n",
    "    return y, agg.index.values \n",
    "\n",
    "\n",
    "class PHPA_Linear:\n",
    "    def __init__(self, lookAhead_ms=LOOKAHEAD_MS, historySize=HISTORY_SIZE, perSync_ms=PER_SYNC_PERIOD_MS):\n",
    "        self.lookAhead_ms = int(lookAhead_ms)\n",
    "        self.historySize = int(historySize)\n",
    "        self.perSync_ms = int(perSync_ms)\n",
    "        self.stepsAhead = max(1, int(np.ceil(self.lookAhead_ms / self.perSync_ms)))\n",
    "\n",
    "    def predict_series(self, y: np.ndarray) -> np.ndarray:\n",
    "        n = len(y)\n",
    "        yhat = np.zeros(n, dtype=float)\n",
    "        if n == 0:\n",
    "            return yhat\n",
    "        yhat[0] = y[0]\n",
    "        for t in range(1, n):\n",
    "            start = max(0, t - self.historySize)\n",
    "            hist = y[start:t]\n",
    "            if len(hist) < 2:\n",
    "                yhat[t] = y[t-1]\n",
    "                continue\n",
    "            xs = np.arange(len(hist), dtype=float)\n",
    "            A = np.vstack([xs, np.ones_like(xs)]).T\n",
    "            try:\n",
    "                slope, intercept = np.linalg.lstsq(A, hist, rcond=None)[0]\n",
    "                future_x = len(hist) - 1 + self.stepsAhead\n",
    "                pred = slope * future_x + intercept\n",
    "            except Exception:\n",
    "                pred = y[t-1]\n",
    "            yhat[t] = pred\n",
    "        return yhat\n",
    "\n",
    "\n",
    "class PHPA_HoltWinters:\n",
    " \n",
    "    def __init__(self, trend_only=HW_TREND_ONLY, seasonal=HW_SEASONAL,\n",
    "                 seasonal_periods=HW_SEASONAL_PERIODS, stored_seasons=HW_STORED_SEASONS,\n",
    "                 min_window=HW_MIN_WINDOW):\n",
    "        self.trend_only = bool(trend_only)\n",
    "        self.seasonal = None if trend_only else str(seasonal)\n",
    "        self.seasonal_periods = int(seasonal_periods)\n",
    "        self.stored_seasons = int(stored_seasons)\n",
    "        self.min_window = int(min_window)\n",
    "\n",
    "    def predict_series(self, y: np.ndarray) -> np.ndarray:\n",
    "        n = len(y)\n",
    "        yhat = np.zeros(n, dtype=float)\n",
    "        if n == 0:\n",
    "            return yhat\n",
    "        yhat[0] = y[0]\n",
    "\n",
    "        if self.seasonal is None:\n",
    "            window = max(self.min_window, 30)\n",
    "        else:\n",
    "            window = max(self.min_window, self.seasonal_periods * max(1, self.stored_seasons))\n",
    "\n",
    "        for t in range(1, n):\n",
    "            start = max(0, t - window)\n",
    "            series = y[start:t]\n",
    "            if len(series) < max(10, (self.seasonal_periods + 2 if self.seasonal else 10)):\n",
    "                yhat[t] = y[t-1]\n",
    "                continue\n",
    "            try:\n",
    "                model = ExponentialSmoothing(\n",
    "                    series,\n",
    "                    trend='add',                      \n",
    "                    seasonal=self.seasonal,           \n",
    "                    seasonal_periods=(self.seasonal_periods if self.seasonal else None),\n",
    "                    initialization_method=\"estimated\"\n",
    "                )\n",
    "                fit = model.fit(optimized=True)      \n",
    "                yhat[t] = float(fit.forecast(1)[0])\n",
    "            except Exception:\n",
    "                yhat[t] = y[t-1]\n",
    "        return yhat\n",
    "\n",
    "def evaluate(y_true, y_hat, name=\"MODEL\"):\n",
    "    y_hat = np.asarray(y_hat, dtype=float)\n",
    "    if CLIP_NEGATIVE:\n",
    "        y_hat = np.maximum(0.0, y_hat)\n",
    "\n",
    "    last_preds = deque(maxlen=40)\n",
    "    mae = MAE(); mape = OnlineMAPE(); wape = OnlineWAPE()\n",
    "    for yt, yh in zip(y_true, y_hat):\n",
    "        mae.update(yt, yh); mape.update(yt, yh); wape.update(yt, yh)\n",
    "        last_preds.append((float(yt), float(yh)))\n",
    "\n",
    "    auto = autoscale_metrics(y_true, y_hat, node_capacity=NODE_CAPACITY)\n",
    "\n",
    "    print(f\"\\n=== {name} (PHPA-like) ===\")\n",
    "    print(\"Last 40 predictions:\")\n",
    "    for i, (yt, yh) in enumerate(last_preds, 1):\n",
    "        print(f\"{i:02d}  Actual={yt:8.2f}  Predicted={yh:8.2f}\")\n",
    "\n",
    "    print(f\"\\nMAE={mae.get():.2f}\")\n",
    "    print(f\"MAPE={mape.get():.2f}%\")\n",
    "    print(f\"WAPE={wape.get():.2f}%\")\n",
    "    print(f\"SLA violations: {auto['sla_violations']}  (rate={auto['sla_rate']:.3f})\")\n",
    "    print(f\"Over-provision (raw mCPU): {auto['overprov_raw']:.2f}\")\n",
    "    print(f\"Over-provision RATE: {100.0*auto['overprov_rate']:.2f}%\")\n",
    "    print(f\"Scaling actions taken: {auto['scaling_actions']}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    y, bins = load_binned_series(\n",
    "        CSV_PATH,\n",
    "        per_sync_ms=PER_SYNC_PERIOD_MS,\n",
    "        how=BIN_AGG,\n",
    "    )\n",
    "\n",
    "    print(f\"Binned series length = {len(y)} (per_sync_ms={PER_SYNC_PERIOD_MS}, agg={BIN_AGG})\")\n",
    "\n",
    "    lin = PHPA_Linear(lookAhead_ms=LOOKAHEAD_MS, historySize=HISTORY_SIZE, perSync_ms=PER_SYNC_PERIOD_MS)\n",
    "    yhat_lin = lin.predict_series(y)\n",
    "    evaluate(y, yhat_lin, name=f\"PHPA Linear (lookAhead={LOOKAHEAD_MS}ms, hist={HISTORY_SIZE})\")\n",
    "\n",
    "    hw = PHPA_HoltWinters(\n",
    "        trend_only=HW_TREND_ONLY,\n",
    "        seasonal=HW_SEASONAL,\n",
    "        seasonal_periods=HW_SEASONAL_PERIODS,\n",
    "        stored_seasons=HW_STORED_SEASONS,\n",
    "        min_window=HW_MIN_WINDOW\n",
    "    )\n",
    "    yhat_hw = hw.predict_series(y)\n",
    "    evaluate(y, yhat_hw, name=f\"Holt-Winters ({'trend-only' if HW_TREND_ONLY else f'seasonal={HW_SEASONAL}, P={HW_SEASONAL_PERIODS}'})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing plotly failed. Interactive plots will not work.\n",
      "18:05:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:05:25 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binned series length = 7225; bin=10000 ms; agg=max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:05:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:05:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:05:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:05:32 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:05:36 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:05:36 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:05:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:05:40 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:05:43 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:05:43 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:05:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:05:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:05:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:05:51 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:05:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:05:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:05:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:05:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:06 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:10 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:17 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:17 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:28 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:32 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:36 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:36 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:40 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:43 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:44 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:51 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:06:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:06:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:07:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:07:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:07:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:07:06 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Prophet (paper baseline) ===\n",
      "Last 40 predictions:\n",
      "01  Actual= 4000.00  Predicted=11089.19\n",
      "02  Actual=32000.00  Predicted=11089.42\n",
      "03  Actual=11400.00  Predicted=11098.17\n",
      "04  Actual=11400.00  Predicted=11104.32\n",
      "05  Actual= 3152.00  Predicted=11105.58\n",
      "06  Actual=11400.00  Predicted=11105.60\n",
      "07  Actual=11400.00  Predicted=11105.65\n",
      "08  Actual=32000.00  Predicted=11105.29\n",
      "09  Actual= 8000.00  Predicted=11093.80\n",
      "10  Actual=11400.00  Predicted=11076.78\n",
      "11  Actual= 3152.00  Predicted=11063.23\n",
      "12  Actual=11908.00  Predicted=11055.77\n",
      "13  Actual= 8000.00  Predicted=11064.81\n",
      "14  Actual=11908.00  Predicted=11066.96\n",
      "15  Actual=11400.00  Predicted=11067.81\n",
      "16  Actual= 8000.00  Predicted=11090.56\n",
      "17  Actual=11908.00  Predicted=11138.32\n",
      "18  Actual=11908.00  Predicted=11172.63\n",
      "19  Actual=11908.00  Predicted=11180.26\n",
      "20  Actual=11908.00  Predicted=11189.76\n",
      "21  Actual=11908.00  Predicted=11193.00\n",
      "22  Actual= 3152.00  Predicted=11196.29\n",
      "23  Actual=11908.00  Predicted=11201.30\n",
      "24  Actual= 3152.00  Predicted=11269.47\n",
      "25  Actual= 3152.00  Predicted=11293.63\n",
      "26  Actual=16000.00  Predicted=11295.79\n",
      "27  Actual=24200.00  Predicted=11297.95\n",
      "28  Actual=11908.00  Predicted=11367.15\n",
      "29  Actual=11908.00  Predicted=11534.92\n",
      "30  Actual=12000.00  Predicted=11648.12\n",
      "31  Actual= 8000.00  Predicted=11722.39\n",
      "32  Actual=11908.00  Predicted=11739.17\n",
      "33  Actual= 4000.00  Predicted=12005.56\n",
      "34  Actual=11400.00  Predicted=12209.89\n",
      "35  Actual= 3152.00  Predicted=12265.78\n",
      "36  Actual=16000.00  Predicted=12305.25\n",
      "37  Actual=11400.00  Predicted=12316.39\n",
      "38  Actual= 6000.00  Predicted=12340.60\n",
      "39  Actual= 3152.00  Predicted=12358.92\n",
      "40  Actual= 3152.00  Predicted=12294.54\n",
      "\n",
      "MAE=4491.70\n",
      "MAPE=74.65%\n",
      "WAPE=44.02%\n",
      "SLA violations: 896  (rate=0.124)\n",
      "Over-provision (raw mCPU): 41686854.00\n",
      "Over-provision RATE: 56.54%\n",
      "Scaling actions taken: 249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:07:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:07:26 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:07:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:07:46 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:08:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:08:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:08:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:08:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:08:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:08:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:09:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:09:15 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:09:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:09:39 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:10:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:10:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:10:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:10:35 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:11:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:11:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:11:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:11:32 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:11:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:12:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:12:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:12:31 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:13:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:13:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:13:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:13:38 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:14:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:14:19 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:14:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:14:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:15:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:15:42 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:16:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:16:20 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:16:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:16:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:17:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:17:30 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:18:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:18:06 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:18:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:18:39 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:19:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:19:16 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:19:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:19:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "18:20:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:20:43 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Hybrid Prophet+LSTM (paper-style) ===\n",
      "Last 40 predictions:\n",
      "01  Actual= 4000.00  Predicted=11161.33\n",
      "02  Actual=32000.00  Predicted=11161.56\n",
      "03  Actual=11400.00  Predicted=11170.32\n",
      "04  Actual=11400.00  Predicted=11176.46\n",
      "05  Actual= 3152.00  Predicted=11177.73\n",
      "06  Actual=11400.00  Predicted=11177.74\n",
      "07  Actual=11400.00  Predicted=11177.80\n",
      "08  Actual=32000.00  Predicted=11177.43\n",
      "09  Actual= 8000.00  Predicted=11165.95\n",
      "10  Actual=11400.00  Predicted=11148.92\n",
      "11  Actual= 3152.00  Predicted=11135.38\n",
      "12  Actual=11908.00  Predicted=11127.91\n",
      "13  Actual= 8000.00  Predicted=11136.95\n",
      "14  Actual=11908.00  Predicted=11139.11\n",
      "15  Actual=11400.00  Predicted=11139.95\n",
      "16  Actual= 8000.00  Predicted=11162.70\n",
      "17  Actual=11908.00  Predicted=11210.46\n",
      "18  Actual=11908.00  Predicted=11244.77\n",
      "19  Actual=11908.00  Predicted=11252.40\n",
      "20  Actual=11908.00  Predicted=11261.90\n",
      "21  Actual=11908.00  Predicted=11265.15\n",
      "22  Actual= 3152.00  Predicted=11268.44\n",
      "23  Actual=11908.00  Predicted=11273.44\n",
      "24  Actual= 3152.00  Predicted=11341.61\n",
      "25  Actual= 3152.00  Predicted=11365.77\n",
      "26  Actual=16000.00  Predicted=11367.93\n",
      "27  Actual=24200.00  Predicted=11370.10\n",
      "28  Actual=11908.00  Predicted=11439.30\n",
      "29  Actual=11908.00  Predicted=11607.06\n",
      "30  Actual=12000.00  Predicted=11720.26\n",
      "31  Actual= 8000.00  Predicted=11794.53\n",
      "32  Actual=11908.00  Predicted=11811.32\n",
      "33  Actual= 4000.00  Predicted=12077.71\n",
      "34  Actual=11400.00  Predicted=12282.03\n",
      "35  Actual= 3152.00  Predicted=12337.92\n",
      "36  Actual=16000.00  Predicted=12377.39\n",
      "37  Actual=11400.00  Predicted=12388.53\n",
      "38  Actual= 6000.00  Predicted=12412.74\n",
      "39  Actual= 3152.00  Predicted=12431.06\n",
      "40  Actual= 3152.00  Predicted=12366.68\n",
      "\n",
      "MAE=4490.48\n",
      "MAPE=74.58%\n",
      "WAPE=44.00%\n",
      "SLA violations: 902  (rate=0.125)\n",
      "Over-provision (raw mCPU): 41629378.00\n",
      "Over-provision RATE: 56.46%\n",
      "Scaling actions taken: 249\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "try:\n",
    "    from prophet import Prophet\n",
    "except Exception:\n",
    "    from fbprophet import Prophet \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "CSV_PATH = 'cluster-trace-gpu-v2023/csv/openb_pod_list_cpu100.csv'\n",
    "NODE_CAPACITY = 8000\n",
    "CLIP_NEGATIVE = True\n",
    "PER_SYNC_PERIOD_MS = 10_000   \n",
    "BIN_AGG = 'max'              \n",
    "PROPHET_DAILY = True\n",
    "PROPHET_WEEKLY = True\n",
    "PROPHET_YEARLY = False\n",
    "PROPHET_SEASONALITY_MODE = 'additive' \n",
    "\n",
    "INIT_WINDOW = 500        \n",
    "REFIT_EVERY = 250       \n",
    "LOOKAHEAD_STEPS = 1     \n",
    "\n",
    "LSTM_LOOKBACK = 48     \n",
    "LSTM_EPOCHS = 8            \n",
    "LSTM_BATCH = 32\n",
    "LSTM_VERBOSE = 0\n",
    "\n",
    "class MAE:\n",
    "    def __init__(self): self.err=0.0; self.n=0\n",
    "    def update(self, y, yhat): self.err += abs(float(y)-float(yhat)); self.n+=1\n",
    "    def get(self): return self.err / max(1, self.n)\n",
    "\n",
    "class OnlineMAPE:\n",
    "    def __init__(self, eps=1e-8): self.eps=eps; self.n=0; self.sum_pe=0.0\n",
    "    def update(self, y, yhat):\n",
    "        y=float(y); yhat=float(yhat)\n",
    "        self.sum_pe += abs(y-yhat)/max(self.eps, abs(y)); self.n += 1\n",
    "    def get(self): return 100.0*self.sum_pe/max(1,self.n)\n",
    "\n",
    "class OnlineWAPE:\n",
    "    def __init__(self, eps=1e-8): self.eps=eps; self.sae=0.0; self.sat=0.0\n",
    "    def update(self, y, yhat):\n",
    "        self.sae += abs(float(y)-float(yhat))\n",
    "        self.sat += abs(float(y))\n",
    "    def get(self): return 100.0*self.sae/max(self.eps,self.sat)\n",
    "\n",
    "def autoscale_metrics(y_true_seq, y_hat_seq, node_capacity=NODE_CAPACITY):\n",
    "    sla_violations=0; overprov_raw=0.0; scaling_actions=0; current_nodes=1\n",
    "    for yt, yh in zip(y_true_seq, y_hat_seq):\n",
    "        need = max(1, int(np.ceil(float(yh)/node_capacity)))\n",
    "        if need*node_capacity < float(yt): sla_violations += 1\n",
    "        overprov_raw += max(0.0, need*node_capacity - float(yt))\n",
    "        if need != current_nodes:\n",
    "            scaling_actions += 1; current_nodes = need\n",
    "    total = len(y_true_seq)\n",
    "    sla_rate = sla_violations / max(1,total)\n",
    "    denom = float(np.sum(y_true_seq)) + 1e-8\n",
    "    overprov_rate = overprov_raw / denom\n",
    "    return dict(sla_violations=sla_violations, sla_rate=sla_rate,\n",
    "                overprov_raw=overprov_raw, overprov_rate=overprov_rate,\n",
    "                scaling_actions=scaling_actions)\n",
    "\n",
    "def _normalize_creation_time_to_ms(ct: np.ndarray) -> np.ndarray:\n",
    "    ct = ct.astype(float); mx = float(np.nanmax(ct)) if len(ct) else 0.0\n",
    "    if mx > 1e15:   ct = ct / 1e6  \n",
    "    elif mx > 1e12: ct = ct / 1e3 \n",
    "    elif mx < 1e9:  ct = ct * 1e3  \n",
    "    return ct\n",
    "\n",
    "def load_binned_series(csv_path=CSV_PATH, per_sync_ms=PER_SYNC_PERIOD_MS, how=BIN_AGG,\n",
    "                       filter_col=None, filter_val=None):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if 'creation_time' not in df.columns:\n",
    "        raise ValueError(\"creation_time required.\")\n",
    "    df['cpu_milli'] = pd.to_numeric(df.get('cpu_milli', 0), errors='coerce')\n",
    "    df['creation_time'] = pd.to_numeric(df['creation_time'], errors='coerce')\n",
    "    df = df.dropna(subset=['creation_time', 'cpu_milli']).copy()\n",
    "\n",
    "    if filter_col and filter_col in df.columns:\n",
    "        df = df[df[filter_col] == filter_val].copy()\n",
    "\n",
    "    df['creation_time'] = _normalize_creation_time_to_ms(df['creation_time'].values).astype(np.int64)\n",
    "    df['bin'] = (df['creation_time'] // int(per_sync_ms)).astype(np.int64)\n",
    "\n",
    "    if how == 'max':\n",
    "        agg = df.groupby('bin', as_index=True)['cpu_milli'].max().sort_index()\n",
    "    else:\n",
    "        agg = df.groupby('bin', as_index=True)['cpu_milli'].mean().sort_index()\n",
    "\n",
    "    y = agg.values.astype(float)\n",
    "    bins = agg.index.values\n",
    "    ds = pd.to_datetime(bins * int(per_sync_ms), unit='ms', utc=True).tz_convert(None)\n",
    "    return y, ds\n",
    "\n",
    "\n",
    "def prophet_walk_forward(y, ds, daily=True, weekly=True, yearly=False,\n",
    "                         seasonality_mode='additive',\n",
    "                         init_window=INIT_WINDOW, refit_every=REFIT_EVERY,\n",
    "                         steps_ahead=LOOKAHEAD_STEPS):\n",
    "    n = len(y)\n",
    "    yhat = np.zeros(n, dtype=float)\n",
    "    yhat[:init_window] = y[:init_window]  \n",
    "\n",
    "    model = None; last_refit = -10**9\n",
    "    history_df = pd.DataFrame({'ds': ds, 'y': y})\n",
    "\n",
    "    for t in range(init_window, n):\n",
    "        if (t - last_refit) >= refit_every or model is None:\n",
    "            m = Prophet(daily_seasonality=daily, weekly_seasonality=weekly, yearly_seasonality=yearly)\n",
    "            m.seasonality_mode = seasonality_mode\n",
    "            m.fit(history_df.iloc[:t])  \n",
    "            model = m; last_refit = t\n",
    "\n",
    "        future_times = [ds[t-1] + pd.to_timedelta(PER_SYNC_PERIOD_MS*steps_ahead, unit='ms')]\n",
    "        future_df = pd.DataFrame({'ds': future_times})\n",
    "        fc = model.predict(future_df)\n",
    "        yhat[t] = float(fc['yhat'].iloc[0])\n",
    "\n",
    "    return yhat\n",
    "def _make_lstm_model(input_len: int):\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(input_len, 1)),\n",
    "        layers.LSTM(50, return_sequences=True),\n",
    "        layers.LSTM(50),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mae')\n",
    "    return model\n",
    "\n",
    "def _build_supervised(seq, lookback):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(seq) - lookback):\n",
    "        X.append(seq[i:i+lookback])\n",
    "        Y.append(seq[i+lookback])\n",
    "    X = np.array(X, dtype=np.float32).reshape(-1, lookback, 1)\n",
    "    Y = np.array(Y, dtype=np.float32).reshape(-1, 1)\n",
    "    return X, Y\n",
    "\n",
    "def prophet_lstm_residual_walk_forward(y, ds,\n",
    "                                       init_window=INIT_WINDOW,\n",
    "                                       refit_every=REFIT_EVERY,\n",
    "                                       steps_ahead=LOOKAHEAD_STEPS,\n",
    "                                       lookback=LSTM_LOOKBACK,\n",
    "                                       epochs=LSTM_EPOCHS,\n",
    "                                       batch=LSTM_BATCH,\n",
    "                                       verbose=LSTM_VERBOSE):\n",
    "    n = len(y)\n",
    "    yhat = np.zeros(n, dtype=float)\n",
    "    yhat[:init_window] = y[:init_window]\n",
    "\n",
    "    last_refit = -10**9\n",
    "    p_model = None\n",
    "    lstm = None\n",
    "    history_df = pd.DataFrame({'ds': ds, 'y': y})\n",
    "    residual_hist = None\n",
    "\n",
    "    for t in range(init_window, n):\n",
    "        if (t - last_refit) >= refit_every or p_model is None or lstm is None:\n",
    "            p = Prophet(daily_seasonality=PROPHET_DAILY, weekly_seasonality=PROPHET_WEEKLY, yearly_seasonality=PROPHET_YEARLY)\n",
    "            p.seasonality_mode = PROPHET_SEASONALITY_MODE\n",
    "            p.fit(history_df.iloc[:t])\n",
    "            hist_fc = p.predict(history_df.iloc[:t][['ds']])\n",
    "            resid = history_df.iloc[:t]['y'].values - hist_fc['yhat'].values\n",
    "            residual_hist = resid.astype(float)\n",
    "            if len(residual_hist) > (lookback + 5):\n",
    "                X, Y = _build_supervised(residual_hist, lookback)\n",
    "                lstm = _make_lstm_model(lookback)\n",
    "                lstm.fit(X, Y, epochs=epochs, batch_size=batch, verbose=verbose)\n",
    "            else:\n",
    "                lstm = None\n",
    "\n",
    "            p_model = p\n",
    "            last_refit = t\n",
    "\n",
    "        future_times = [ds[t-1] + pd.to_timedelta(PER_SYNC_PERIOD_MS*steps_ahead, unit='ms')]\n",
    "        future_df = pd.DataFrame({'ds': future_times})\n",
    "        p_fc = p_model.predict(future_df)\n",
    "        base = float(p_fc['yhat'].iloc[0])\n",
    "\n",
    "        if lstm is not None:\n",
    "            past_resid = residual_hist[-lookback:]\n",
    "            if len(past_resid) < lookback:\n",
    "                past = np.pad(past_resid, (lookback - len(past_resid), 0))\n",
    "            else:\n",
    "                past = past_resid\n",
    "            x = past.reshape(1, lookback, 1).astype(np.float32)\n",
    "            res_next = float(lstm.predict(x, verbose=0)[0,0])\n",
    "        else:\n",
    "            res_next = 0.0\n",
    "\n",
    "        yhat[t] = base + res_next\n",
    "\n",
    "    return yhat\n",
    "\n",
    "def evaluate(y_true, y_hat, name=\"MODEL\"):\n",
    "    y_hat = np.array(y_hat, dtype=float)\n",
    "    if CLIP_NEGATIVE:\n",
    "        y_hat = np.maximum(0.0, y_hat)\n",
    "\n",
    "    last_preds = deque(maxlen=40)\n",
    "    mae = MAE(); mape = OnlineMAPE(); wape = OnlineWAPE()\n",
    "    for yt, yh in zip(y_true, y_hat):\n",
    "        mae.update(yt, yh); mape.update(yt, yh); wape.update(yt, yh)\n",
    "        last_preds.append((float(yt), float(yh)))\n",
    "    auto = autoscale_metrics(y_true, y_hat, node_capacity=NODE_CAPACITY)\n",
    "\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(\"Last 40 predictions:\")\n",
    "    for i, (yt, yh) in enumerate(last_preds, 1):\n",
    "        print(f\"{i:02d}  Actual={yt:8.2f}  Predicted={yh:8.2f}\")\n",
    "    print(f\"\\nMAE={mae.get():.2f}\")\n",
    "    print(f\"MAPE={mape.get():.2f}%\")\n",
    "    print(f\"WAPE={wape.get():.2f}%\")\n",
    "    print(f\"SLA violations: {auto['sla_violations']}  (rate={auto['sla_rate']:.3f})\")\n",
    "    print(f\"Over-provision (raw mCPU): {auto['overprov_raw']:.2f}\")\n",
    "    print(f\"Over-provision RATE: {100.0*auto['overprov_rate']:.2f}%\")\n",
    "    print(f\"Scaling actions taken: {auto['scaling_actions']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    y, ds = load_binned_series(CSV_PATH, per_sync_ms=PER_SYNC_PERIOD_MS, how=BIN_AGG)\n",
    "    print(f\"Binned series length = {len(y)}; bin={PER_SYNC_PERIOD_MS} ms; agg={BIN_AGG}\")\n",
    "    yhat_p = prophet_walk_forward(\n",
    "        y, ds,\n",
    "        daily=PROPHET_DAILY, weekly=PROPHET_WEEKLY, yearly=PROPHET_YEARLY,\n",
    "        seasonality_mode=PROPHET_SEASONALITY_MODE,\n",
    "        init_window=INIT_WINDOW, refit_every=REFIT_EVERY,\n",
    "        steps_ahead=LOOKAHEAD_STEPS\n",
    "    )\n",
    "    evaluate(y, yhat_p, name=\"Prophet (paper baseline)\")\n",
    "    yhat_pl = prophet_lstm_residual_walk_forward(\n",
    "        y, ds,\n",
    "        init_window=INIT_WINDOW,\n",
    "        refit_every=REFIT_EVERY,\n",
    "        steps_ahead=LOOKAHEAD_STEPS,\n",
    "        lookback=LSTM_LOOKBACK,\n",
    "        epochs=LSTM_EPOCHS,\n",
    "        batch=LSTM_BATCH,\n",
    "        verbose=LSTM_VERBOSE\n",
    "    )\n",
    "    evaluate(y, yhat_pl, name=\"Hybrid Prophet+LSTM (paper-style)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
